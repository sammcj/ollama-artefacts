# If you can run it, use the 32b version (qwen2.5-coder:32b-instruct-q6_K) which is more powerful.
OLLAMA_MODEL=qwen2.5-coder:14b-instruct-q6_K
OLLAMA_HOST=http://localhost:11434
MAX_TOKENS=4096
OPEN_BROWSER=True
